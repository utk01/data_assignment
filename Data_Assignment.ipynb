{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c80844b-d7b7-4079-a42e-736d053bcc82",
   "metadata": {},
   "source": [
    "# Create Spark Session and Load data in pyspark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0668fe8e-edc7-40b9-8305-064e0addaf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- image: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- style: struct (nullable = true)\n",
      " |    |-- Color:: string (nullable = true)\n",
      " |    |-- Format:: string (nullable = true)\n",
      " |    |-- Size:: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: long (nullable = true)\n",
      " |-- verified: boolean (nullable = true)\n",
      " |-- vote: string (nullable = true)\n",
      "\n",
      "+----------+-----+-------+--------------------+-----------+--------------+------------------+--------------------+--------------------+--------------+--------+----+\n",
      "|      asin|image|overall|          reviewText| reviewTime|    reviewerID|      reviewerName|               style|             summary|unixReviewTime|verified|vote|\n",
      "+----------+-----+-------+--------------------+-----------+--------------+------------------+--------------------+--------------------+--------------+--------+----+\n",
      "|0001388703| NULL|    5.0|This is a great c...|12 22, 2013|A1ZCPG3D3HGRSS|    mark l. massey|{NULL,  Audio CD,...|    Great worship cd|    1387670400|    true|NULL|\n",
      "|0001388703| NULL|    5.0|So creative!  Lov...|09 11, 2013| AC2PL52NKPL29|      Norma Mushen|{NULL,  Audio CD,...|Gotta listen to t...|    1378857600|    true|NULL|\n",
      "|0001388703| NULL|    5.0|Keith Green, gone...| 03 2, 2013|A1SUZXBDZSDQ3A|Herbert W. Shurley|{NULL,  Audio CD,...|Great approach st...|    1362182400|    true|NULL|\n",
      "|0001388703| NULL|    5.0|Keith Green had h...| 12 2, 2012|A3A0W7FZXM0IZW|    Mary M Raybell|{NULL,  Audio CD,...|   Great A must have|    1354406400|    true|NULL|\n",
      "|0001388703| NULL|    5.0|Keith Green / So ...| 01 7, 2012|A12R54MKO17TW0|          J. Bynum|{NULL,  Audio CD,...|A great one from ...|    1325894400|   false|   6|\n",
      "+----------+-----+-------+--------------------+-----------+--------------+------------------+--------------------+--------------------+--------------+--------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, length\n",
    "\n",
    "\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AmazonReviews\")\\\n",
    "    .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\") \\\n",
    "    .config(\"spark.hadoop.home.dir\",\"file:///\") \\\n",
    "    .config(\"spark.jars\", \"C:/Users/Unnati/anaconda3/envs/spark_env/Lib/site-packages/pyspark/jars/postgresql-42.7.1.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read the reviews file\n",
    "reviews_df = spark.read.json(\"../Downloads/Digital_Music.json.gz\")\n",
    "\n",
    "# Display schema and first few rows\n",
    "reviews_df.printSchema()\n",
    "reviews_df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff30c385-835a-4231-99ab-6028ea9742db",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e4fcb9-fffe-41e9-ae98-65e7a7ea2367",
   "metadata": {},
   "source": [
    "# Item having least rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186ea52c-327f-47c6-81b3-c9c09744f9f6",
   "metadata": {},
   "source": [
    "### a) Items recieved a rating equal to least rating in enitre dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a6e3dec-6a98-4ce8-b937-41c9fca7d7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|      asin|overall|\n",
      "+----------+-------+\n",
      "|B0011Z3ETM|    1.0|\n",
      "|B0012328SQ|    1.0|\n",
      "|B00136LDKQ|    1.0|\n",
      "|B001O03NRM|    1.0|\n",
      "|B0020VTEZO|    1.0|\n",
      "|B002WXJU4A|    1.0|\n",
      "|B004Z6KSF2|    1.0|\n",
      "|B00534REC0|    1.0|\n",
      "|B006JHVRNW|    1.0|\n",
      "|B00ANGVEJM|    1.0|\n",
      "|B00EE96DWM|    1.0|\n",
      "|B00GR0FD86|    1.0|\n",
      "|B00MHGH50I|    1.0|\n",
      "|B00O6DQIYE|    1.0|\n",
      "|B00W8DLF7Y|    1.0|\n",
      "|B0108UOUBG|    1.0|\n",
      "|B000079BCM|    1.0|\n",
      "|B00065L59Y|    1.0|\n",
      "|B000MM1H1W|    1.0|\n",
      "|B000QOLYN2|    1.0|\n",
      "+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26043"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import min\n",
    "\n",
    "# Find the minimum rating\n",
    "min_rating = reviews_df.agg(min(\"overall\")).first()[0]\n",
    "\n",
    "# Filter items with the overall minimum rating and take distinct items\n",
    "least_rated_items = reviews_df.filter(col(\"overall\") == min_rating).select(\"asin\", \"overall\").distinct()\n",
    "\n",
    "least_rated_items.show()\n",
    "\n",
    "least_rated_items.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70e77ec-67de-45bf-aab4-1d2cd58836d5",
   "metadata": {},
   "source": [
    "### b) Items with least average rating (for items having atleast 10 ratings )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bad88c4-dd87-472d-abc2-b9e741f0c0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+\n",
      "|      asin|avg_rating|num_ratings|\n",
      "+----------+----------+-----------+\n",
      "|B00S33PD6W|       1.0|         73|\n",
      "|B00NIJY63W|       1.0|         44|\n",
      "|B012VAF74U|       1.0|         11|\n",
      "+----------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, count\n",
    "\n",
    "# Set a threshold for the minimum number of ratings an item should have\n",
    "min_ratings_threshold = 10  # You can adjust this based on your dataset and requirements\n",
    "\n",
    "# Calculate average rating and count of ratings per item\n",
    "item_ratings_agg = (\n",
    "    reviews_df.groupBy(\"asin\")\n",
    "    .agg(avg(\"overall\").alias(\"avg_rating\"), count(\"overall\").alias(\"num_ratings\"))\n",
    ")\n",
    "\n",
    "# Filter items with at least the minimum number of ratings\n",
    "filtered_items = item_ratings_agg.filter(col(\"num_ratings\") >= min_ratings_threshold)\n",
    "\n",
    "# Find the minimum average rating\n",
    "min_avg_rating = filtered_items.agg({\"avg_rating\": \"min\"}).collect()[0][0]\n",
    "\n",
    "# Filter items with the minimum average rating\n",
    "least_avg_rated_items = (\n",
    "    filtered_items\n",
    "    .filter(col(\"avg_rating\") == min_avg_rating)\n",
    "    .select(\"asin\", \"avg_rating\", \"num_ratings\")\n",
    ")\n",
    "\n",
    "least_avg_rated_items.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe17461-3306-4b80-8fcd-d13d96e85b8b",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03175f92-0c40-4367-90ad-70d23545f502",
   "metadata": {},
   "source": [
    "# Item having most rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f248d198-43c0-4b2c-90c9-fb57925739c7",
   "metadata": {},
   "source": [
    "### a) Items recieved a rating equal to max rating in enitre dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9a2d823-bca1-4673-85ba-2a7ef5ef85dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|      asin|overall|\n",
      "+----------+-------+\n",
      "|B000QONMQ4|    5.0|\n",
      "|B000QVL4NU|    5.0|\n",
      "|B000S43HH6|    5.0|\n",
      "|B000SXHB6K|    5.0|\n",
      "|B000SX8DW6|    5.0|\n",
      "|B000TEIZ0Y|    5.0|\n",
      "|B000V61688|    5.0|\n",
      "|B000V615YS|    5.0|\n",
      "|B000VRQSVM|    5.0|\n",
      "|B000VZWMZ0|    5.0|\n",
      "|B000W1AO4Y|    5.0|\n",
      "|B000WLF1UG|    5.0|\n",
      "|B000XEI154|    5.0|\n",
      "|B000Z7S78U|    5.0|\n",
      "|B00113SLBA|    5.0|\n",
      "|B0011W7H5C|    5.0|\n",
      "|B001229998|    5.0|\n",
      "|B00122IQP6|    5.0|\n",
      "|B00122YSJ4|    5.0|\n",
      "|B00123FVMQ|    5.0|\n",
      "+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "392580"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import max\n",
    "\n",
    "# Find the maximum rating\n",
    "max_rating = reviews_df.agg(max(\"overall\")).first()[0]\n",
    "\n",
    "# Filter items with the overall maximum rating and take distinct items\n",
    "most_rated_items = reviews_df.filter(col(\"overall\") == max_rating).select(\"asin\", \"overall\").distinct()\n",
    "\n",
    "most_rated_items.show()\n",
    "\n",
    "most_rated_items.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b70981d-a0a2-46dc-abfc-ae8ede01fa99",
   "metadata": {},
   "source": [
    "### b) Items with max average rating (for items having atleast 10 ratings )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "359a9d10-bc01-4a32-b608-37a5da3dcbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+\n",
      "|      asin|avg_rating|num_ratings|\n",
      "+----------+----------+-----------+\n",
      "|B000YOIQEY|       5.0|         20|\n",
      "|B0011W4304|       5.0|         14|\n",
      "|B00137IN62|       5.0|         18|\n",
      "|B00137QLPW|       5.0|         12|\n",
      "|B004ABW9V8|       5.0|         17|\n",
      "|B00E7H70F0|       5.0|         11|\n",
      "|B00GAVAJC2|       5.0|         42|\n",
      "|B017L0HNE2|       5.0|         11|\n",
      "|B010XMNW8Q|       5.0|         10|\n",
      "|B000X6TZ6G|       5.0|         36|\n",
      "|B00122NUXE|       5.0|         12|\n",
      "|B001EL6940|       5.0|         11|\n",
      "|B001R0IINI|       5.0|         11|\n",
      "|B005F1TI9I|       5.0|         11|\n",
      "|B006U60MK6|       5.0|         11|\n",
      "|B00MXBUWV6|       5.0|         14|\n",
      "|B00PXO0NM8|       5.0|         10|\n",
      "|B0159RK5OE|       5.0|         10|\n",
      "|B00021Z7TQ|       5.0|         12|\n",
      "|B00123N8Z8|       5.0|         12|\n",
      "+----------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2294"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, count\n",
    "\n",
    "# Set a threshold for the minimum number of ratings an item should have\n",
    "max_ratings_threshold = 10  # You can adjust this based on your dataset and requirements\n",
    "\n",
    "# Calculate average rating and count of ratings per item\n",
    "item_ratings_agg = (\n",
    "    reviews_df.groupBy(\"asin\")\n",
    "    .agg(avg(\"overall\").alias(\"avg_rating\"), count(\"overall\").alias(\"num_ratings\"))\n",
    ")\n",
    "\n",
    "# Filter items with at least the minimum number of ratings\n",
    "filtered_items = item_ratings_agg.filter(col(\"num_ratings\") >= min_ratings_threshold)\n",
    "\n",
    "# Find the minimum average rating\n",
    "max_avg_rating = filtered_items.agg({\"avg_rating\": \"max\"}).collect()[0][0]\n",
    "\n",
    "# Filter items with the maximum average rating\n",
    "max_avg_rated_items = (\n",
    "    filtered_items\n",
    "    .filter(col(\"avg_rating\") == max_avg_rating)\n",
    "    .select(\"asin\", \"avg_rating\", \"num_ratings\")\n",
    ")\n",
    "\n",
    "max_avg_rated_items.show()\n",
    "max_avg_rated_items.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1daa4f-6adb-46c5-b89c-08259da0eeeb",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a2cc79-69fc-4ba8-9274-43d5916e6d48",
   "metadata": {},
   "source": [
    "# Items having longest reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622b0265-83da-4ffb-ae9e-50c25e2903e9",
   "metadata": {},
   "source": [
    "### a) Item with the longest review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2bb1f87-09c3-4382-a090-d087b300215e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------+--------------------+-----------+--------------+-------------+--------------------+--------------------+--------------+--------+----+-------------+\n",
      "|      asin|image|overall|          reviewText| reviewTime|    reviewerID| reviewerName|               style|             summary|unixReviewTime|verified|vote|review_length|\n",
      "+----------+-----+-------+--------------------+-----------+--------------+-------------+--------------------+--------------------+--------------+--------+----+-------------+\n",
      "|B00FZ11C0G| NULL|    3.0|This is my novel-...|03 26, 2013|A2NAWWR03ZBUTB|Just Some Guy|{NULL,  Audio CD,...|What if Thomas Ke...|    1364256000|    true|  26|        32501|\n",
      "+----------+-----+-------+--------------------+-----------+--------------+-------------+--------------------+--------------------+--------------+--------+----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "longest_review_item = reviews_df.withColumn(\"review_length\", length(\"reviewText\")).orderBy(col(\"review_length\").desc()).limit(1)\n",
    "\n",
    "longest_review_item.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9a2128-dfa5-4e37-a8c1-add1db7dc153",
   "metadata": {},
   "source": [
    "### b) Item with the max average review length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643d8e32-d9dc-4ea4-a428-e73fea6f013a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+-----------------+\n",
      "|      asin|avg_rating|num_ratings|avg_review_length|\n",
      "+----------+----------+-----------+-----------------+\n",
      "|B0018IE3JM|       4.0|          1|          29701.0|\n",
      "+----------+----------+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import length,avg,count\n",
    "\n",
    "# Calculate the length of reviews per item\n",
    "item_reviews_length = (\n",
    "    reviews_df.groupBy(\"asin\")\n",
    "    .agg(avg(\"overall\").alias(\"avg_rating\"), count(\"overall\").alias(\"num_ratings\"), avg(length(\"reviewText\")).alias(\"avg_review_length\"))\n",
    ")\n",
    "\n",
    "# Find the maximum average review length\n",
    "max_avg_review_length = item_reviews_length.agg({\"avg_review_length\": \"max\"}).collect()[0][0]\n",
    "\n",
    "# Filter items with the maximum average review length\n",
    "longest_reviews_items = (\n",
    "    item_reviews_length\n",
    "    .filter(col(\"avg_review_length\") == max_avg_review_length)\n",
    "    .select(\"asin\", \"avg_rating\", \"num_ratings\", \"avg_review_length\")\n",
    ")\n",
    "\n",
    "longest_reviews_items.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a63e03-f51c-4a46-ae85-e4594350aa71",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a2fa78-da38-4fa6-adfb-7f438c2028b3",
   "metadata": {},
   "source": [
    "# Transform: change the date MM-DD-YYYY format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc61de17-d443-4d1f-b72a-a731aa150c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------+--------------------+----------+--------------+-------------------+--------------------+--------------------+--------------+--------+----+\n",
      "|      asin|image|overall|          reviewText|reviewTime|    reviewerID|       reviewerName|               style|             summary|unixReviewTime|verified|vote|\n",
      "+----------+-----+-------+--------------------+----------+--------------+-------------------+--------------------+--------------------+--------------+--------+----+\n",
      "|0001388703| NULL|    5.0|This is a great c...|12-22-2013|A1ZCPG3D3HGRSS|     mark l. massey|{NULL,  Audio CD,...|    Great worship cd|    1387670400|    true|NULL|\n",
      "|0001388703| NULL|    5.0|So creative!  Lov...|09-11-2013| AC2PL52NKPL29|       Norma Mushen|{NULL,  Audio CD,...|Gotta listen to t...|    1378857600|    true|NULL|\n",
      "|0001388703| NULL|    5.0|Keith Green, gone...|03-02-2013|A1SUZXBDZSDQ3A| Herbert W. Shurley|{NULL,  Audio CD,...|Great approach st...|    1362182400|    true|NULL|\n",
      "|0001388703| NULL|    5.0|Keith Green had h...|12-02-2012|A3A0W7FZXM0IZW|     Mary M Raybell|{NULL,  Audio CD,...|   Great A must have|    1354406400|    true|NULL|\n",
      "|0001388703| NULL|    5.0|Keith Green / So ...|01-07-2012|A12R54MKO17TW0|           J. Bynum|{NULL,  Audio CD,...|A great one from ...|    1325894400|   false|   6|\n",
      "|0001388703| NULL|    5.0|Clever,inspired a...|07-08-2009|A25ZT87OMIPLNX| Mark the Pizza guy|{NULL,  MP3 Music...|              AWSOME|    1247011200|   false|   2|\n",
      "|0001388703| NULL|    1.0|This tape can har...|05-14-2009|A3NVGWKHLULDHR|Therese M. Teasdale|{NULL,  Audio Cas...|         Shame Shame|    1242259200|   false|NULL|\n",
      "|0001388703| NULL|    5.0|Keith Green is a ...|05-04-2008| AT7OB43GHKIUA|   William G. Simon|{NULL,  Audio CD,...|Heartfelt, Passio...|    1209859200|   false|  10|\n",
      "|0001388703| NULL|    5.0|             Pleased|09-18-2015|A1H3X1TW6Y7HD8|       Nancy Abbott|{NULL,  Audio CD,...|          Five Stars|    1442534400|    true|NULL|\n",
      "|0001388703| NULL|    1.0|Buy the CD.  Do n...|05-15-2015| AZ3T21W6CW0MW|               None|{NULL,  MP3 Music...|Buy the CD.  Do n...|    1431648000|    true|NULL|\n",
      "|0001388703| NULL|    5.0|Takes me back to ...|03-13-2015|A2W6V65OFOZ12M|       amharris1962|{NULL,  MP3 Music...|            Love it!|    1426204800|    true|NULL|\n",
      "|0001388703| NULL|    5.0|What can ever go ...|11-04-2014|A1DOF5GHOWGMW6|                  p|{NULL,  Audio CD,...|                LOVE|    1415059200|    true|NULL|\n",
      "|0001388703| NULL|    5.0|This has always b...|10-12-2014| A4V08BR7LZ6D9| James M. Daugherty|{NULL,  Audio CD,...|So You Wanna Go B...|    1413072000|    true|NULL|\n",
      "|0001388703| NULL|    5.0|Keith Green was a...|09-23-2014| AJO3UG6FR5C7R|     Steven M. Gray|{NULL,  MP3 Music...|His music is stil...|    1411430400|    true|NULL|\n",
      "|0001388703| NULL|    4.0|A favorite cd now...|08-25-2014|A106GSY0H5E2R4|                MSH|{NULL,  Audio CD,...|Wonderful collect...|    1408924800|    true|NULL|\n",
      "|0001388703| NULL|    3.0|The CD was not in...|05-26-2014|A33D2MKED6ZENS| Grateful Grandmama|{NULL,  Audio CD,...|Review on \"So You...|    1401062400|    true|NULL|\n",
      "|0001388703| NULL|    5.0|The passion and i...|04-15-2014|A27P44I54RUMDC|            B. Ross|{NULL,  Audio CD,...|No one like Keith...|    1397520000|    true|NULL|\n",
      "|0001388703| NULL|    5.0|Keith's music is ...|02-25-2014|A2A3M3HVVGT9XY|              Bryan|{NULL,  MP3 Music...|      Never Gets Old|    1393286400|    true|   2|\n",
      "|0001526146| NULL|    5.0|This is music fro...|01-20-2017|A2HVNCQUR2J4NL|       Brenda Mudra|                NULL|        Great. music|    1484870400|    true|NULL|\n",
      "|0001526146| NULL|    5.0|I love Dallas Hol...|10-03-2016| A50DSLM71EAVO|    Amazon Customer|                NULL|          Five Stars|    1475452800|    true|NULL|\n",
      "+----------+-----+-------+--------------------+----------+--------------+-------------------+--------------------+--------------------+--------------+--------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import date_format,to_date\n",
    "\n",
    "\n",
    "\n",
    "# Transform: Change the date format to MM-DD-YYYY\n",
    "reviews_df_transformed = reviews_df.withColumn(\"reviewTime\", to_date(reviews_df[\"reviewTime\"], \"MM dd, yyyy\")).withColumn(\"reviewTime\", date_format(\"reviewTime\", \"MM-dd-yyyy\"))\n",
    "\n",
    "reviews_df_transformed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4d77c4-1365-4074-b764-711a69fa6e0b",
   "metadata": {},
   "source": [
    "-----\n",
    "# Time Trend Analysis of Ratings (Commulative Average Ratings )eeds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab429e4-d094-4942-b440-7a60aa2c853c",
   "metadata": {},
   "source": [
    "The operation involves\n",
    "\n",
    "1. Extracting the year and month from the review date.\n",
    "2. Using a window function to calculate the cumulative average rating over time for each item.\n",
    "\n",
    "This operation demonstrates how user ratings have evolved for different items over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2447349-8844-4ecf-9cb0-60f030a094ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+---------------------+\n",
      "|      asin|year_month|avg_rating|cumulative_avg_rating|\n",
      "+----------+----------+----------+---------------------+\n",
      "|0633039640|   10-2010|       5.0|                  5.0|\n",
      "|0819815586|   01-2014|       5.0|                  5.0|\n",
      "|0819815586|   01-2018|       1.0|                  3.0|\n",
      "|0819815586|   08-2013|       5.0|   3.6666666666666665|\n",
      "|0898005965|   06-2010|       4.5|                  4.5|\n",
      "|0910558337|   03-2018|       5.0|                  5.0|\n",
      "|0910558337|   04-2017|       2.5|                 3.75|\n",
      "|0972433503|   12-2013|       1.0|                  1.0|\n",
      "|097761493X|   11-2013|       5.0|                  5.0|\n",
      "|097761493X|   12-2013|       5.0|                  5.0|\n",
      "|0983470812|   08-2011|       5.0|                  5.0|\n",
      "|0984099239|   03-2011|       4.0|                  4.0|\n",
      "|1070313335|   12-2010|       5.0|                  5.0|\n",
      "|1570198268|   04-2008|       5.0|                  5.0|\n",
      "|1570198985|   11-2013|       5.0|                  5.0|\n",
      "|1570198985|   12-2016|       5.0|                  5.0|\n",
      "|1570199280|   01-2015|       5.0|                  5.0|\n",
      "|1570199280|   07-2014|       5.0|                  5.0|\n",
      "|1570199280|   08-2014|       5.0|                  5.0|\n",
      "|1570199280|   10-2012|       5.0|                  5.0|\n",
      "+----------+----------+----------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date, avg,year,month\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "reviews_df_transformed = reviews_df_transformed.withColumn(\"year_month\",  date_format(to_date(reviews_df_transformed[\"reviewTime\"], \"MM-dd-yyyy\"), \"MM-yyyy\"))\n",
    "\n",
    "\n",
    "# Define a window specification for the aggregation\n",
    "\n",
    "window_spec = Window().partitionBy(\"asin\").orderBy(\"year_month\").rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "# Calculate the cumulative average rating over time for each item\n",
    "cumulative_avg_ratings = (\n",
    "    reviews_df_transformed.groupBy(\"asin\", \"year_month\")\n",
    "    .agg(avg(\"overall\").alias(\"avg_rating\"))\n",
    "    .withColumn(\"cumulative_avg_rating\", F.avg(\"avg_rating\").over(window_spec))\n",
    ")\n",
    "\n",
    "cumulative_avg_ratings.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd19e53c-01e9-4a50-ac33-80d07e1763fe",
   "metadata": {},
   "source": [
    "------\n",
    "# Save the data into a postgres table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea5519c5-99df-420d-bb19-eee70509325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JDBC connection properties\n",
    "jdbc_url = \"jdbc:postgresql://localhost:5432/postgres\"\n",
    "jdbc_properties = {\"user\": \"postgres\", \"password\": \"12345678\", \"driver\": \"org.postgresql.Driver\"}\n",
    "\n",
    "# Save the DataFrame to PostgreSQL\n",
    "flattened_df=reviews_df_transformed.withColumn(\"style_color\",col(\"style.Color:\"))\\\n",
    "                        .withColumn(\"style_color\",col(\"style.Color:\"))\\\n",
    "                        .withColumn(\"style_color\",col(\"style.Color:\"))\\\n",
    "                        .drop(\"style\")\n",
    "\n",
    "flattened_df.write.jdbc(url=jdbc_url, table=\"your_table\", mode=\"overwrite\", properties=jdbc_properties)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd929bd9-0753-4827-b5e7-96c0259c4ef9",
   "metadata": {},
   "source": [
    "------\n",
    "# Save Data in parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f08e115-2470-42c7-92f5-40949aa55006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the whole file into Parquet format\n",
    "\n",
    "flattened_df.write.mode(\"overwrite\").parquet(\"../Downloads/Transformed_Digital_Music.parquet\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
